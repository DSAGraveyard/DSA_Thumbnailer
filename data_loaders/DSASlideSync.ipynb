{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import os,csv,sys\n",
    "import openslide\n",
    "import dsa_mongo_common_functions as dsa\n",
    "import cdsa_loader_helper_functions as cdsa_helpers\n",
    "import pprint\n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "dsa_load_errors_db = client['DSA_LoadErrors']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cdsa_loader_helper_functions' from 'cdsa_loader_helper_functions.pyc'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(dsa)\n",
    "reload(cdsa_helpers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 Potential Patient directories were identified\n"
     ]
    }
   ],
   "source": [
    "## This is specific to a given fle system and or structurme\n",
    "slide_root = '/GLOBAL_SCRATCH/ADRC/'  ##Base Path for Slides\n",
    "dsa_slide_db = client['DSA_Slide_DB']  ### These need to be configured for the specific project\n",
    "\n",
    "### To generalize this, need to describe organization, most common will be  PATIENT/STAIN_TYPE as subdirectories\n",
    "subj_dir_list = [x for x in os.listdir(slide_root) if os.path.isdir(os.path.join(slide_root,x))]\n",
    "print len(subj_dir_list),\"Potential Patient directories were identified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_rawslide_lists( slide_root_path ):\n",
    "        \"\"\"project_name is passed along with the potentially more than one root image path for ndpi files\"\"\"\n",
    "        slide_files = []\n",
    "\n",
    "        slide_root_path  = slide_root_path.rstrip('/')\n",
    "        print slide_root_path\n",
    "        for dpath, dnames, fnames in os.walk( slide_root_path, followlinks=True):\n",
    "                \n",
    "                for file in fnames:\n",
    "                    if '.ndpi' in file or '.svs' in file:\n",
    "                                slide_files.append(dpath +'/'+file)\n",
    "        print len(slide_files),\"SVS or NDPI files were located\"\n",
    "        return slide_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADRC61-124', 'ADRC50-10', 'ADRC61-128', 'ADRC50-40', 'ADRC51-60', '@eaDir', 'ADRC60-150', 'ADRC61-120', 'ADRC57-85', 'ADRC55-200', 'ADRC49-07', 'ADRC50-11', 'ADRC51-2', 'ADRC51-134', '.ipynb_checkpoints', 'SamMarch20', 'ADRC61-139', 'ADRC61-125', 'ADRC53-300', 'ADRC56-112', 'ADRC43-24', 'ADRC61-73', 'ADRC62-74', 'ADRC61-84', 'ADRC62-14', 'ADRC60-179', 'ADRC49-04', 'ADRC56-97', 'ADRC51-06', 'ADRC36-04', 'ADRC59-164', 'ADRC56-18', 'ADRC59-81', 'ADRC62-110', 'ADRC61-143', 'ADRC47-60', 'ADRC62-6', 'ADRC60-48', 'ADRC61-97', 'ADRC62-64', 'ADRC54-125', 'newcerebptstoload', 'ADRC61-71', 'ADRC60-110', 'ADRC61-20', 'ADRC56-06', 'ADRC53-55', 'ADRC59-8', 'ADRC60-137', 'ADRC60-160', 'ADRC61-70', 'ADRC61-75', 'ADRC55-100', 'ADRC56-160', 'ADRC51-10', 'ADRC39-44', 'ADRC58-146', 'ADRC60-88', 'ADRC61-41', 'ADRC62-62', 'ADRC61-112', 'ADRC55-194', 'ADRC60-83', 'ADRC50-41', 'ADRC60-38', 'ADRC61-60', 'ADRC62-32', 'ADRC54-76', 'NickSlidesFeb20', 'ADRC59-35', 'ADRC47-61', 'ADRC55-108', 'ADRC61-83', 'ADRC51-94', 'ADRC59-91', 'ADRC58-119', 'ADRC53-95', 'ADRC53-385', 'ADRC60-151', 'ADRC56-52', 'ADRC60-81', 'ADRC50-21', 'ADRC50-14', 'ADRC50-19', 'ADRC60-56', 'ADRC51-152', 'ADRC61-59', 'ADRC58-162', 'ADRC54-99', 'ADRC62-85', 'Neuro_Degen_Training_Slides', 'ADRC59-155', 'ADRC61-81', 'ADRC62-120', 'ADRC54-155', 'Miscellaneous', 'ADRC60-129', 'ADRC53-138', 'ADRC57-48', 'ADRC60-63', 'NickMarch18', 'ADRC54-48', 'ADRC51-33']\n"
     ]
    }
   ],
   "source": [
    "print subj_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "def generate_file_md5(rootdir, filename, blocksize=2**20):\n",
    "    m = hashlib.md5()\n",
    "    with open( os.path.join(rootdir, filename) , \"rb\" ) as f:\n",
    "        while True:\n",
    "            buf = f.read(blocksize)\n",
    "            if not buf:\n",
    "                break\n",
    "            m.update( buf )\n",
    "    return m.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'hashlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f0f52fb489c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/GLOBAL_SCRATCH/ADRC/ADRC53-300/Tau/ADRC53-300_1_TAU.ndpi'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgenerate_file_md5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/GLOBAL_SCRATCH/ADRC/ADRC53-300/Tau/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ADRC53-300_1_TAU.ndpi'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-6a9b9d60c790>\u001b[0m in \u001b[0;36mgenerate_file_md5\u001b[1;34m(rootdir, filename, blocksize)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgenerate_file_md5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrootdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmd5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrootdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'hashlib' is not defined"
     ]
    }
   ],
   "source": [
    "# nm = '/GLOBAL_SCRATCH/ADRC/ADRC53-300/Tau/ADRC53-300_1_TAU.ndpi'\n",
    "# generate_file_md5('/GLOBAL_SCRATCH/ADRC/ADRC53-300/Tau/','ADRC53-300_1_TAU.ndpi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADRC61-124 is being processed /GLOBAL_SCRATCH/ADRC/ADRC61-124\n",
      "106 SVS or NDPI files were located\n",
      "\u001b[KTotal Processed: 44  Newly Processed: 44 Dup Slides or Already Loaded: 0  RESCANNED Slides 0"
     ]
    }
   ],
   "source": [
    "### So this creates a document WITHIN the current database to store raw information about the slides\n",
    "## Now that I think about this, I really should not store the filename but the File Hash as I.. want to change the filenames\n",
    "\n",
    "for sd in subj_dir_list:\n",
    "    print sd,\"is being processed\",\n",
    "    curr_svs_slide_list = find_rawslide_lists(  os.path.join(slide_root,sd)  )\n",
    "    slides_processed = newly_processed = dup_slide = rescanned_slides =  0\n",
    "    for sld in curr_svs_slide_list:\n",
    "\n",
    "        slide_name = os.path.basename(sld)\n",
    "        qry = dsa_slide_db['RawSlideData'].find_one( {'slide_name':slide_name})\n",
    "        fs = os.path.getsize(sld)\n",
    "        ### Going to add the filesize... so I make the assumption if the name and the filesize are the same,\n",
    "        ### I have the same file..\n",
    "        #print qry\n",
    "        if not qry:\n",
    "            \n",
    "            #md5Checksum = dsa.md5sum(sld)\n",
    "            (openslide_could_open, width, height, filesize, orig_resolution, slide_name,md5, sld_properties) = cdsa_helpers.openslide_test_file_mongo( sld, 'ndpi', client)\n",
    "            if openslide_could_open:\n",
    "                prep_type = 'Unknown'\n",
    "                slide_metadata = { 'slide_w_path': sld, 'slide_name': slide_name, 'file_size':fs, 'width':width, 'height':height,\n",
    "                                 'orig_resolution': orig_resolution, 'sld_properties': cdsa_helpers.clean_openslide_keys ( sld_properties), 'slide_md5': md5, 'prep_type': prep_type\n",
    "                                 }\n",
    "                dsa_slide_db['RawSlideData'].insert_one(slide_metadata)\n",
    "                newly_processed +=1 \n",
    "            else:\n",
    "                print \"UNABLE TO OPEN FILE??\",sld\n",
    "                ###Need to flag/load this in to an error database\n",
    "\n",
    "        else:\n",
    "            fs = os.path.getsize(sld)\n",
    "            ## Double check if file size matches\n",
    "#             if qry['file_size'] != fs:\n",
    "#                 #print \"File size mismatch??\",fs,qry['file_size'],qry['slide_w_path'],sld\n",
    "#                 load_errors_db['rescanned_slides'].insert_one( {'loaded_slide': qry['slide_w_path'], 'rescanned_slide': sld}             )\n",
    "#                 rescanned_slides +=1 \n",
    "#             else:\n",
    "#                 dup_slide +=1\n",
    "\n",
    "    \n",
    "        slides_processed +=1        \n",
    "        output = \"Total Processed: %d  Newly Processed: %d Dup Slides or Already Loaded: %d  RESCANNED Slides %d\" % (slides_processed, newly_processed, dup_slide, rescanned_slides )\n",
    "        dsa.LinePrinter(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dsa_slide_db['DSA_Slide_Data'].delete_many({})\n",
    "#print dsa_slide_db['DSA_Slide_Data'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### I now want to reformat all of this data to make it more useful for DSA ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_slides = dsa_slide_db['RawSlideData'].find()\n",
    "\n",
    "## Since this is pretty easy to recreate, I'm going to empty the current database\n",
    "\n",
    "dsa_slide_db['DSA_Slide_Data'].delete_many({})\n",
    "\n",
    "for s in all_slides:\n",
    "    slide_dict = {}\n",
    "    pt_id = s['slide_w_path'].split('/')[-3]\n",
    "    stain_type = s['slide_w_path'].split('/')[-2]\n",
    "    slide_dict = s\n",
    "    slide_dict.pop('_id',None)\n",
    "    \n",
    "    slide_dict['pt_id'] = pt_id\n",
    "    slide_dict['stain_type'] = stain_type\n",
    "    ### Obfuscating the global file path so everything is relative to some base path for the archive/\n",
    "    slide_dict['thumbnail_image'] = '/thumbnail/' + s['slide_w_path'].replace('/GLOBAL_SCRATCH/ADRC/','')\n",
    "    slide_dict['slide_w_path'] = '/DZIMS/' + s['slide_w_path'].replace('/GLOBAL_SCRATCH/ADRC/','')+'.dzi'\n",
    "    dsa_slide_db['DSA_Slide_Data'].insert_one(slide_dict)\n",
    "\n",
    "    #       var html = sld_info.slide_name + '#' + sld_info.slide_w_path+ '#' + sld_info.slide_name + '#' + sld_info.thumbnail_image;\n",
    "##    viewer.open('/DZIMS/ADRC50-21/pTDP/OS00-21_14_pTDP_1to10k.ndpi.dzi')\n",
    "###      var html = sld_info.slide_name + '#' + sld_info.slide_w_path+ '#' + sld_info.slide_name + '#' + sld_info.thumbnail_image;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dsa_slide_db['DSA_Slide_Data'].distinct('pt_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur= dsa_slide_db['DSA_Slide_Data'].find({'pt_id':'ADRC50-10'})\n",
    "for c in cur:\n",
    "    print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "## Going to create a cleanup and /or reformatted collection for the DSA Viewer\n",
    "for s in dsa_slide_db['ADRC'].find():\n",
    "    keys_of_interest = ['width','height']\n",
    "    print s['slide_w_path']\n",
    "    print s.keys()\n",
    "    sys.exit()\n",
    "###\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
