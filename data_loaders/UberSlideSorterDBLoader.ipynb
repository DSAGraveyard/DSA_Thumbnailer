{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os,sys,pymongo\n",
    "import DSAHelperFunctions as dsa\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Local Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Paths and Name for Archive and Location of Slides and Pyramids\n",
    "archive_name= 'UberSliderSorter'  ### This obviously changes for a given slide set\n",
    "WSI_root = '/TCGA_MIRROR/'  ##WholeSlide Image Root Directory\n",
    "### Will eventually make this a list...\n",
    "## Create Database  Connections\n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "archive_db = client[archive_name]\n",
    "## Within the ArrchiveDB I will have subcollections for SlideData, MetaData and Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 folder sets are available\n",
      "['frozen_sections', 'tcga-data.nci.nih.gov', 'MOUSE_GLIOMA', 'EMORY_BIOBANK', 'DJ_SLIDE_DATA', 'WINSHIP_BIOBANK', 'TCGA_FLAT', 'TCGA_FLAT_NONCONFORMING']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'slide_w_path_1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This assumes taht within a given WholeSlideImage directory, the top level directory is the basic grouping for a slide\n",
    "wsi_dirs = [x for x in os.listdir(WSI_root) if os.path.isdir(os.path.join(WSI_root,x)) ]\n",
    "print len(wsi_dirs),'folder sets are available'\n",
    "\n",
    "wsi_dirs.remove('@Recycle')\n",
    "wsi_dirs.remove('.git')\n",
    "print wsi_dirs\n",
    "archive_db['RawSlideData'].create_index('slide_w_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkSlideStatus( wsiFileList, rootCollxn, dbPtr):\n",
    "    \"\"\"This accepts a whole slide image with the full file path, and the root Collection\n",
    "    and a pointer to the mongoDatabase housing the raw slide data, it will then update/amend as needed\"\"\"\n",
    "    slides_processed = dup_slide = newly_processed = rescanned_slides =  bad_slides = 0\n",
    "    for wsi in wsiFileList:\n",
    "        ### Going to get file Stats\n",
    "        qry = dbPtr['RawSlideData'][rootCollxn].find_one( {'slide_w_path':wsi})\n",
    "        if not qry:  ## Means I couldn't find this file loaded\n",
    "            ###Double check it's not an ivnalid filee\n",
    "            \n",
    "            (openslide_could_open, sldMetadata) = dsa.OpenslideGetImageMetadata( wsi)\n",
    "            \n",
    "            if openslide_could_open:\n",
    "                ### Need to inject in some other keys\n",
    "                prep_type = \"Unknown\"\n",
    "                sldMetadata['slide_w_path'] = wsi\n",
    "                sldMetadata['file_size'] = os.path.getsize(wsi)\n",
    "                sldMetadata['slide_name'] = os.path.basename(wsi)\n",
    "                sldMetadata['scanProperties'] = dsa.clean_openslide_keys( sldMetadata['scanProperties'])\n",
    "                newly_processed +=1 \n",
    "                dbPtr['RawSlideData'][rootCollxn].insert_one(sldMetadata)\n",
    "            else:\n",
    "                sldMetadata['slide_w_path'] = wsi\n",
    "                sldMetadata['OpenslideFailedOpen'] = True\n",
    "\n",
    "                dbPtr['LoadErrorDB'][rootCollxn].insert_one(sldMetadata)\n",
    "                dbPtr['RawSlideData'][rootCollxn].insert_one(sldMetadata)\n",
    "                \n",
    "                bad_slides +=1\n",
    "\n",
    "        else:\n",
    "            ### See if the other slide matches  #print \"Image seems to have been loaded?\"  This is if I find two slides with same name with difts sizes\n",
    "            rescanned_slides +=1\n",
    "        slides_processed +=1        \n",
    "        output = \"Total Processed: %d  Newly Processed: %d Dup Slides or Already Loaded: %d  RESCANNED Slides %d badSlides %d\" % (slides_processed, newly_processed, dup_slide, rescanned_slides, bad_slides )\n",
    "        dsa.LinePrinter(output)\n",
    "    print ### Need this at the end of the block to advacne the dsa/LinePrinter comment abobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen_sections\n",
      "\n",
      "tcga-data.nci.nih.gov\n",
      "\u001b[KTotal Processed: 107455  Newly Processed: 0 Dup Slides or Already Loaded: 0  RESCANNED Slides 107455 badSlides 0\n",
      "MOUSE_GLIOMA\n",
      "\u001b[KTotal Processed: 284  Newly Processed: 0 Dup Slides or Already Loaded: 0  RESCANNED Slides 284 badSlides 0\n",
      "EMORY_BIOBANK\n",
      "\u001b[KTotal Processed: 232  Newly Processed: 0 Dup Slides or Already Loaded: 0  RESCANNED Slides 232 badSlides 0\n",
      "DJ_SLIDE_DATA\n",
      "\n",
      "WINSHIP_BIOBANK\n",
      "\u001b[KTotal Processed: 10  Newly Processed: 0 Dup Slides or Already Loaded: 0  RESCANNED Slides 10 badSlides 0\n",
      "TCGA_FLAT\n",
      "\u001b[KTotal Processed: 32307  Newly Processed: 0 Dup Slides or Already Loaded: 0  RESCANNED Slides 32307 badSlides 0\n",
      "TCGA_FLAT_NONCONFORMING\n",
      "\u001b[KTotal Processed: 288  Newly Processed: 0 Dup Slides or Already Loaded: 0  RESCANNED Slides 288 badSlides 0\n"
     ]
    }
   ],
   "source": [
    "reload(dsa)\n",
    "\n",
    "### For debugging I'm going to load the entire slide list into memory...\n",
    "for wsiRD in wsi_dirs:\n",
    "    ### I am going to use the Top Level Directory i.e. wsiRD as the primary collection/folder\n",
    "    ### and grab all the children files\n",
    "    print wsiRD\n",
    "    wsiFileList = dsa.get_filepaths(os.path.join(WSI_root,wsiRD))\n",
    "    checkSlideStatus(wsiFileList, wsiRD, archive_db)\n",
    "    ### Now iterate through the fileList and update/amend files as needed if they are not in the database\n",
    "    \n",
    "### u'openslide.objective-power': u'40',\n",
    "#paths = [os.path.join(path,fn) for fn in next(os.walk(path))[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wsiFileList = dsa.get_filepaths(os.path.join(WSI_root,'TCGA_FLAT'))\n",
    "print len(wsiFileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkSlideStatus(wsiFileList,'TCGA_FLAT', archive_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(dsa)\n",
    "wsi='/TCGA_MIRROR/TCGA_FLAT/coad/TCGA-A6-5656-01Z-00-DX1.8a8ebf52-8217-4288-8886-7eefa6cdfdca.svs'\n",
    "(openslide_could_open, sldMetadata) = dsa.OpenslideGetImageMetadata( wsi)\n",
    "print openslide_could_open\n",
    "print sldMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#             if qry['file_size'] != fs:\n",
    "#                 #print \"File size mismatch??\",fs,qry['file_size'],qry['slide_w_path'],sld\n",
    "#                 load_errors_db['rescanned_slides'].insert_one( {'loaded_slide': qry['slide_w_path'], 'rescanned_slide': sld}             )\n",
    "#                 rescanned_slides +=1 \n",
    "#             else:\n",
    "#                 dup_slide +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = archive_db['RawSlideData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### This is a composite view that combines the pyramid and original NDPI tables\n",
    "### This may eventually link in other information abut the slides as well\n",
    "combined_db = client[archive_name]\n",
    "### The combo view combines data from the slide and pyramid database...\n",
    "pyr_collections = [x for x in combined_db.collection_names() if 'PyramidData' in x]\n",
    "\n",
    "## Iterate through the pyramid table for each collection\n",
    "iip_base_url = 'http://node15.cci.emory.edu/cgi-bin/iipsrv.fcgi'\n",
    "    \n",
    "for pyr_c in pyr_collections:\n",
    "    ## Now iterate through the list of pyramids within each group\n",
    "    print pyr_c\n",
    "    \n",
    "    cur_pyrgrp_ptr = combined_db[pyr_c].find()\n",
    "    for pyr in cur_pyrgrp_ptr:\n",
    "        #print pyr\n",
    "        #sys.exit()\n",
    "        ### Now I am only going to grab a subset of the fields... not all are really needed by the CDSA currently\n",
    "        ## The SlideURL and thumbnail are built frmo the other fields...\n",
    "        #'http://node15.cci.emory.edu/cgi-bin/iipsrv.fcgi?FIF=/bigdata2/PYRAMIDS/CDSA/DLBC_Frozen/nationwidechildrens.org_DLBC.tissue_images.Level_1.248.0.0/TCGA-FA-8693-01A-01-BS1.263ab76a-8168-4f72-8147-8c2a44d0948b.svs.dzi.tif&WID=200&CVT=jpeg\n",
    "        thumbnail_url = \"%s?FIF=%s&WID=200&CVT=jpeg\" % (iip_base_url, pyr['pyramid_w_path'] )\n",
    "        \n",
    "        slide_url = \"%s?DeepZoom=%s.dzi\" % (iip_base_url, pyr['pyramid_w_path'] )\n",
    "        #print slide_url\n",
    "        slide_basename = pyr['pyramid_name'].split('.')[0] ## This basically just returns the part of the slide before the dot.. removes the extensions and UID\n",
    "        folder = pyr_c.replace('PyramidData.','')\n",
    "        \n",
    "        prep_type = 'Unk'\n",
    "        \n",
    "        cdsa_rec = { 'slide_id': pyr['_id'], 'slide_url': '', 'annotation': False,  'thumbnail': 'TBD', \n",
    "                      'image_width': pyr['width'], 'image_height': pyr['height'], 'pyramid_filename': pyr['pyramid_name'],\n",
    "                       'tumor_type' : folder, 'prep_type': prep_type, 'slide_url': slide_url,\n",
    "                       'thumbnail_image': thumbnail_url, 'slide_name': slide_basename\n",
    "                   }\n",
    "        #print cdsa_rec\n",
    "        print folder\n",
    "        combined_db['Merged'][folder].insert_one(cdsa_rec)\n",
    "        \n",
    "        \n",
    "        #sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ### CHECK OUT FILE 2620 +-10 this is for PRAD\n",
    "# pyramid_root = '/PYRAMIDS/EmoryBioBank/'\n",
    "\n",
    "\n",
    "\n",
    "# for sc in ndpi_collections:\n",
    "#     #print \"ANALYZING\", sc,\"Tumor Type\"\n",
    "#     ### First get the slide collection data, this is at the tumor type level\n",
    "#     ## The pyramid collections are organized a bit differently, so I need to map the collection names between the systems\n",
    "#     print sc\n",
    "#     ndpi_files = slide_db[sc].find()\n",
    "#     #print ndpi_files\n",
    "#     ndpi_w_pyramid = 0\n",
    "#     needs_pyramid = 0\n",
    "#     for ndpi in ndpi_files:\n",
    "#         #print ndpi\n",
    "#         slide_name = ndpi['slide_name']\n",
    "#         prep_type = ndpi['prep_type']\n",
    "#         #print svs\n",
    "#         pyramid_name = slide_name+'.dzi.tif'\n",
    "#         print pyramid_name\n",
    "        \n",
    "# ###        #print \"Looking for\",pyramid_name,pyramid_collection_name\n",
    "#         pyr_query =  slide_db['PyramidData'][sc].find_one({'pyramid_name': pyramid_name})\n",
    "#         if pyr_query:\n",
    "#             #print pyr_query, slide_name, prep_type\n",
    "#             ndpi_w_pyramid +=1\n",
    "#         else:\n",
    "#             needs_pyramid +=1\n",
    "#             slide_w_path = ndpi['slide_w_path']\n",
    "#             prep_type = 'UNK'\n",
    "#             ### doing a set of nonintuitive transformatinos for the pyramid output directory\n",
    "            \n",
    "#             archive_dir = os.path.dirname(slide_w_path).replace(ndpi_root,'')\n",
    "#             #archive_dir = archive_dir\n",
    "#             ## #Need to make sure output directory is created or the conversion failes\n",
    "#             output_pyr_dir = os.path.join(pyramid_root, archive_dir )\n",
    "#             print output_pyr_dir\n",
    "#             if not os.path.isdir(output_pyr_dir):\n",
    "#                 print \"Need to make output dir!\",output_pyr_dir\n",
    "                \n",
    "#                 os.makedirs(output_pyr_dir)\n",
    "#                 vips_fp.write( \"mkdir -p \"+output_pyr_dir+\"\\r\\n\" )\n",
    "#                 ### This code may need some thought... I am running this process as dagutman or root... may\n",
    "#                 ### Screw up the file system\n",
    "            \n",
    "#             pyr_w_path  = os.path.join( output_pyr_dir, pyramid_name)\n",
    "                        \n",
    "                        \n",
    "#             vips_fp.write( \"vips im_extract_bands \"+slide_w_path+pyr_w_path+\":jpeg:75,tile:256x256,pyramid,,,,8 0 3\\r\\n\" )\n",
    "\n",
    "#     print sc,\"needs\",needs_pyramid,\"and these svs files seem to have pyramids\",ndpi_w_pyramid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_for_pyramid(slide_w_path,base_folder):\n",
    "    \"\"\"This will take an input string, and given a slide, will search for a corresponding pyramid tiff, if not it will output\n",
    "    the syntax to create one\"\"\"\n",
    "    print slide_w_path,\"is the slide I am on\"\n",
    "    \n",
    "    slide_name = os.path.basename(slide_w_path)\n",
    "    slide_dir = os.path.dirname(slide_w_path)\n",
    "    pyramid_name = slide_name+'.dzi.tif'\n",
    "    print pyramid_name,slide_dir,slide_name\n",
    "    \n",
    "    ### First check and see if I have already loaded a pyramid for this image into the corresponding table\n",
    "    pyr_query =  archive_db['PyramidData'][base_folder].find_one({'pyramid_name': pyramid_name})\n",
    "    print pyr_query\n",
    "    if pyr_query:\n",
    "        print \"Pyramid EXISTS!\"\n",
    "        return True\n",
    "    else:\n",
    "        ### Need to either load or create the pyramid\n",
    "    \n",
    "        ##In this case I am assuming there is a one to one correspondence between where I want pyramids to\n",
    "        ##Live and where I want the original slides to live; with the only diff being the root of the path being\n",
    "        # NDPI_ROOT or PYRAMID_ROOT    The files also have a 1:1 correspondence except for the extension being .dzi.tif\n",
    "        pyramid_dir = os.path.dirname(slide_w_path).replace(ndpi_root,pyramid_root)\n",
    "        pyramid_name = slide_name+'.dzi.tif'\n",
    "        print pyramid_dir, slide_dir\n",
    "        pyr_w_path  = os.path.join( pyramid_dir, pyramid_name)\n",
    "        \n",
    "        if not os.path.isfile(pyr_w_path):\n",
    "            print \"vips im_extract_bands \"+slide_w_path+' '+pyr_w_path+\":jpeg:75,tile:256x256,pyramid,,,,8 0 3\\r\\n\"\n",
    "            vips_fp.write( \"vips im_extract_bands \"+slide_w_path+' '+pyr_w_path+\":jpeg:75,tile:256x256,pyramid,,,,8 0 3\\r\\n\" )\n",
    "        else:\n",
    "            print \"I NEED TO LOAD THIS INTO THE DATABASE\"\n",
    "            fs = os.path.getsize(pyr_w_path)\n",
    "            (openslide_could_open, width, height, filesize, orig_resolution, slide_name,md5, pyramid_properties) = cdsa_helpers.openslide_test_file_mongo( pyr_w_path, 'pyramid', client)\n",
    "\n",
    "            pyramid_metadata = { 'pyramid_w_path': pyr_w_path, 'pyramid_name': pyramid_name, 'file_size':fs, 'width':width, 'height':height,\n",
    "                                 'pyramid_properties': cdsa_helpers.clean_openslide_keys ( pyramid_properties), 'slide_md5': md5, \n",
    "                                 'conversion_info': 'TBD'\n",
    "                                 }\n",
    "                #print slide_metadata\n",
    "            archive_db['PyramidData'][base_folder].insert_one(pyramid_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_for_pyramid('/TCGA_MIRROR/EMORY_BIOBANK/Emory_BioBank/GBM_GLIOMA_PROJECT/11-1_PNC2.ndpi','GBM_GLIOMA_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Displays the current collections in the database\n",
    "print archive_db.collection_names(False)\n",
    "#archive_db['SlideData.DigitalBioBank'].drop()  ## If I need to drop anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print curr_svs_slide_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print archive_db.collection_names()\n",
    "\n",
    "pyramid_folders = [x for x in archive_db.collection_names() if 'PyramidData' in x]\n",
    "print pyramid_folders"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
